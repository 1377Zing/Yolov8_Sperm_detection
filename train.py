#-------------------------------------#
# Train the dataset
#-------------------------------------#
import datetime
import os
from functools import partial

import numpy as np
import torch
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from nets.yolo import YoloBody
from nets.yolo_training import (Loss, ModelEMA, get_lr_scheduler,
                                set_optimizer_lr, weights_init)
from utils.callbacks import EvalCallback, LossHistory
from utils.dataloader import YoloDataset, yolo_dataset_collate
from utils.utils import (download_weights, get_classes, seed_everything,
                         show_config, worker_init_fn)
from utils.utils_fit import fit_one_epoch

if __name__ == "__main__":
    #---------------------------------#
    # Cuda: Whether to use Cuda.
    # Set to False if no GPU is available.
    #---------------------------------#
    Cuda = True
    #----------------------------------------------#
    # Seed: Used to fix the random seed.
    # Ensures the same results for each independent training.
    #----------------------------------------------#
    seed = 11
    #---------------------------------------------------------------------#
    # distributed: Specifies whether to use single-machine multi-GPU distributed training.
    # Terminal commands only support Ubuntu. Use CUDA_VISIBLE_DEVICES to specify GPUs on Ubuntu.
    # Windows uses DP mode by default and does not support DDP.
    # DP mode:
    #   Set distributed = False
    #   Run in terminal: CUDA_VISIBLE_DEVICES=0,1 python train.py
    # DDP mode:
    #   Set distributed = True
    #   Run in terminal: CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 train.py
    #---------------------------------------------------------------------#
    distributed = False
    #---------------------------------------------------------------------#
    # sync_bn: Whether to use sync_bn. Available for multi-GPU in DDP mode.
    #---------------------------------------------------------------------#
    sync_bn = False
    #---------------------------------------------------------------------#
    # fp16: Whether to use mixed precision training.
    # Reduces about half of the GPU memory. Requires PyTorch 1.7.1 or higher.
    #---------------------------------------------------------------------#
    fp16 = False
    #---------------------------------------------------------------------#
    # classes_path: Points to the txt file in model_data, related to the training dataset.
    # Modify it to match your dataset before training.
    #---------------------------------------------------------------------#
    classes_path = 'model_data/voc_classes.txt'
    model_path = '/root/autodl-tmp/111/logs/ep060-loss2.768-val_loss2.546.pth'
    #------------------------------------------------------#
    # input_shape: Input shape, must be a multiple of 32.
    #------------------------------------------------------#
    input_shape = [640, 640]
    #------------------------------------------------------#
    # phi: Version of YOLOv8 to use.
    #------------------------------------------------------#
    phi = 'm'
    #----------------------------------------------------------------------------------------------------------------------------#
    # pretrained: Whether to use the pre-trained weights of the backbone network.
    # Loaded when building the model.
    # If model_path is set, the backbone weights are not loaded, and pretrained has no effect.
    # If model_path is not set and pretrained = True, only the backbone is loaded for training.
    # If model_path is not set, pretrained = False, and Freeze_Train = False, training starts from scratch without freezing the backbone.
    #----------------------------------------------------------------------------------------------------------------------------#
    pretrained = False
    #------------------------------------------------------------------#
    # mosaic: Mosaic data augmentation.
    # mosaic_prob: Probability of using mosaic data augmentation in each step, default 50%.
    #
    # mixup: Whether to use mixup data augmentation, only effective when mosaic = True.
    # Applies mixup to the images after mosaic augmentation.
    # mixup_prob: Probability of using mixup after mosaic, default 50%.
    # Total mixup probability is mosaic_prob * mixup_prob.
    #
    # special_aug_ratio: Refer to YoloX. Since the training images generated by Mosaic deviate from the real distribution of natural images.
    # When mosaic = True, mosaic is enabled within the special_aug_ratio range.
    # Defaults to the first 70% of epochs, e.g., 70 epochs out of 100.
    #------------------------------------------------------------------#
    mosaic = True
    mosaic_prob = 0.5
    mixup = True
    mixup_prob = 0.5
    special_aug_ratio = 0.7
    #------------------------------------------------------------------#
    # label_smoothing: Label smoothing. Usually below 0.01, e.g., 0.01, 0.005.
    #------------------------------------------------------------------#
    label_smoothing = 0

    Init_Epoch = 0
    Freeze_Epoch = 0
    Freeze_batch_size = 0
    UnFreeze_Epoch = 200
    Unfreeze_batch_size = 32
    #------------------------------------------------------------------#
    # Freeze_Train: Whether to perform frozen training.
    # Default is to freeze the backbone first and then unfreeze for training.
    #------------------------------------------------------------------#
    Freeze_Train = False

    #------------------------------------------------------------------#
    # Other training parameters related to learning rate, optimizer, and learning rate decay.
    #------------------------------------------------------------------#
    #------------------------------------------------------------------#
    # Init_lr: Maximum learning rate of the model.
    # Min_lr: Minimum learning rate of the model, default is 0.01 of the maximum learning rate.
    #------------------------------------------------------------------#
    Init_lr = 1e-2
    Min_lr = Init_lr * 0.01
    #------------------------------------------------------------------#
    # optimizer_type: Type of optimizer to use, options are 'adam' and 'sgd'.
    # Recommended Init_lr = 1e-3 for Adam optimizer.
    # Recommended Init_lr = 1e-2 for SGD optimizer.
    # momentum: Momentum parameter used in the optimizer.
    # weight_decay: Weight decay to prevent overfitting.
    # Set to 0 when using Adam optimizer.
    #------------------------------------------------------------------#
    optimizer_type = "sgd"
    momentum = 0.937
    weight_decay = 5e-4
    #------------------------------------------------------------------#
    # lr_decay_type: Type of learning rate decay, options are 'step' and 'cos'.
    #------------------------------------------------------------------#
    lr_decay_type = "cos"
    #------------------------------------------------------------------#
    # save_period: Save the weights every few epochs.
    #------------------------------------------------------------------#
    save_period = 10
    #------------------------------------------------------------------#
    # save_dir: Folder to save weights and log files.
    #------------------------------------------------------------------#
    save_dir = 'logs'
    #------------------------------------------------------------------#
    # eval_flag: Whether to evaluate during training, evaluation is performed on the validation set.
    # Evaluation experience is better after installing pycocotools.
    # eval_period: Evaluate every few epochs. Not recommended to evaluate too frequently.
    # Evaluation takes time and slows down training.
    # The mAP obtained here is different from that in get_map.py for two reasons:
    # (1) The mAP here is for the validation set.
    # (2) The evaluation parameters here are set conservatively to speed up evaluation.
    #------------------------------------------------------------------#
    eval_flag = True
    eval_period = 10
    #------------------------------------------------------------------#
    # num_workers: Set whether to use multi-threading for data reading.
    # Speeds up data reading but consumes more memory.
    # Set to 2 or 0 for computers with less memory.
    #------------------------------------------------------------------#
    num_workers = 4

    #------------------------------------------------------#
    # train_annotation_path: Paths and labels of training images.
    # val_annotation_path: Paths and labels of validation images.
    #------------------------------------------------------#
    train_annotation_path = '2007_train.txt'
    val_annotation_path = '2007_val.txt'

    seed_everything(seed)
    #------------------------------------------------------#
    # Set the GPUs to use.
    #------------------------------------------------------#
    ngpus_per_node = torch.cuda.device_count()
    if distributed:
        dist.init_process_group(backend="nccl")
        local_rank = int(os.environ["LOCAL_RANK"])
        rank = int(os.environ["RANK"])
        device = torch.device("cuda", local_rank)
        if local_rank == 0:
            print(f"[{os.getpid()}] (rank = {rank}, local_rank = {local_rank}) training...")
            print("Gpu Device Count : ", ngpus_per_node)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        local_rank = 0
        rank = 0

    #------------------------------------------------------#
    # Get classes and anchors.
    #------------------------------------------------------#
    class_names, num_classes = get_classes(classes_path)

    #----------------------------------------------------#
    # Download pre-trained weights.
    #----------------------------------------------------#
    if pretrained:
        if distributed:
            if local_rank == 0:
                download_weights(phi)
            dist.barrier()
        else:
            download_weights(phi)

    #------------------------------------------------------#
    # Create the YOLO model.
    #------------------------------------------------------#
    model = YoloBody(input_shape, num_classes, phi, pretrained=pretrained)

    if model_path != '':
        #------------------------------------------------------#
        # Download weight files as described in README.
        #------------------------------------------------------#
        if local_rank == 0:
            print('Load weights {}.'.format(model_path))

        #------------------------------------------------------#
        # Load weights based on the keys of pre-trained weights and the model.
        #------------------------------------------------------#
        model_dict = model.state_dict()
        pretrained_dict = torch.load(model_path, map_location=device)
        load_key, no_load_key, temp_dict = [], [], {}
        for k, v in pretrained_dict.items():
            if k in model_dict.keys() and np.shape(model_dict[k]) == np.shape(v):
                temp_dict[k] = v
                load_key.append(k)
            else:
                no_load_key.append(k)
        model_dict.update(temp_dict)
        model.load_state_dict(model_dict)
        #------------------------------------------------------#
        # Show the keys that failed to load.
        #------------------------------------------------------#
        if local_rank == 0:
            print("\nSuccessful Load Key:", str(load_key)[:500], "……\nSuccessful Load Key Num:", len(load_key))
            print("\nFail To Load Key:", str(no_load_key)[:500], "……\nFail To Load Key num:", len(no_load_key))
            print("\nWarm reminder: It's normal that the head part is not loaded, but it's an error if the backbone part is not loaded.")

    #----------------------#
    # Get the loss function.
    #----------------------#
    yolo_loss = Loss(model)
    #----------------------#
    # Record the loss.
    #----------------------#
    if local_rank == 0:
        time_str = datetime.datetime.strftime(datetime.datetime.now(), '%Y_%m_%d_%H_%M_%S')
        log_dir = os.path.join(save_dir, "loss_" + str(time_str))
        loss_history = LossHistory(log_dir, model, input_shape=input_shape)
    else:
        loss_history = None

    #------------------------------------------------------------------#
    # torch 1.2 does not support amp. It's recommended to use torch 1.7.1 or higher for correct use of fp16.
    #------------------------------------------------------------------#
    if fp16:
        from torch.cuda.amp import GradScaler as GradScaler
        scaler = GradScaler()
    else:
        scaler = None

    model_train = model.train()
    #----------------------------#
    # Sync BatchNorm across multiple GPUs.
    #----------------------------#
    if sync_bn and ngpus_per_node > 1 and distributed:
        model_train = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model_train)
    elif sync_bn:
        print("Sync_bn is not supported on a single GPU or without distributed training.")

    if Cuda:
        if distributed:
            #----------------------------#
            # Run in multi-GPU parallel mode.
            #----------------------------#
            model_train = model_train.cuda(local_rank)
            model_train = torch.nn.parallel.DistributedDataParallel(model_train, device_ids=[local_rank], find_unused_parameters=True)
        else:
            model_train = torch.nn.DataParallel(model)
            cudnn.benchmark = True
            model_train = model_train.cuda()

    #----------------------------#
    # Weight smoothing.
    #----------------------------#
    ema = ModelEMA(model_train)

    #---------------------------#
    # Read the txt files corresponding to the dataset.
    #---------------------------#
    with open(train_annotation_path, encoding='utf-8') as f:
        train_lines = f.readlines()
    with open(val_annotation_path, encoding='utf-8') as f:
        val_lines = f.readlines()
    num_train = len(train_lines)
    num_val = len(val_lines)

    if local_rank == 0:
        show_config(
            classes_path=classes_path, model_path=model_path, input_shape=input_shape,
            Init_Epoch=Init_Epoch, Freeze_Epoch=Freeze_Epoch, UnFreeze_Epoch=UnFreeze_Epoch, Freeze_batch_size=Freeze_batch_size, Unfreeze_batch_size=Unfreeze_batch_size, Freeze_Train=Freeze_Train,
            Init_lr=Init_lr, Min_lr=Min_lr, optimizer_type=optimizer_type, momentum=momentum, lr_decay_type=lr_decay_type,
            save_period=save_period, save_dir=save_dir, num_workers=num_workers, num_train=num_train, num_val=num_val
        )
        #---------------------------------------------------------#
        # Total training epochs refer to the total number of times of traversing the entire dataset.
        # Total training steps refer to the total number of gradient descents.
        # Each training epoch contains several training steps, and each training step performs one gradient descent.
        # Only the minimum recommended training epochs are given here, with no upper limit. Only the unfrozen part is considered in the calculation.
        #----------------------------------------------------------#
        wanted_step = 5e4 if optimizer_type == "sgd" else 1.5e4
        total_step = num_train // Unfreeze_batch_size * UnFreeze_Epoch
        if total_step <= wanted_step:
            if num_train // Unfreeze_batch_size == 0:
                raise ValueError('The dataset is too small to train. Please expand the dataset.')
            wanted_epoch = wanted_step // (num_train // Unfreeze_batch_size) + 1
            print("\n[Warning] When using the %s optimizer, it's recommended to set the total training steps to over %d." % (optimizer_type, wanted_step))
            print("[Warning] The total training data size for this run is %d, Unfreeze_batch_size is %d, and a total of %d Epochs will be trained. The calculated total training steps are %d." % (num_train, Unfreeze_batch_size, UnFreeze_Epoch, total_step))
            print("[Warning] Since the total training steps are %d, less than the recommended %d, it's recommended to set the total epochs to %d." % (total_step, wanted_step, wanted_epoch))

    #------------------------------------------------------#
    # The backbone feature extraction network features are general. Frozen training can speed up training.
    # It also prevents the weights from being damaged in the early stage of training.
    # Init_Epoch is the starting epoch.
    # Freeze_Epoch is the number of epochs for frozen training.
    # UnFreeze_Epoch is the total number of training epochs.
    # If OOM or insufficient GPU memory occurs, reduce the Batch_size.
    #------------------------------------------------------#
    if True:
        UnFreeze_flag = False
        #------------------------------------#
        # Freeze part of the model for training.
        #------------------------------------#
        if Freeze_Train:
            for param in model.backbone.parameters():
                param.requires_grad = False

        #-------------------------------------------------------------------#
        # If not performing frozen training, directly set batch_size to Unfreeze_batch_size.
        #-------------------------------------------------------------------#
        batch_size = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size

        #-------------------------------------------------------------------#
        # Adjust the learning rate adaptively based on the current batch_size.
        #-------------------------------------------------------------------#
        nbs = 64
        lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2
        lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4
        Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)
        Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)

        #---------------------------------------#
        # Select the optimizer based on optimizer_type.
        #---------------------------------------#
        pg0, pg1, pg2 = [], [], []
        for k, v in model.named_modules():
            if hasattr(v, "bias") and isinstance(v.bias, nn.Parameter):
                pg2.append(v.bias)
            if isinstance(v, nn.BatchNorm2d) or "bn" in k:
                pg0.append(v.weight)
            elif hasattr(v, "weight") and isinstance(v.weight, nn.Parameter):
                pg1.append(v.weight)
        optimizer = {
            'adam': optim.Adam(pg0, Init_lr_fit, betas=(momentum, 0.999)),
          'sgd': optim.SGD(pg0, Init_lr_fit, momentum=momentum, nesterov=True)
        }[optimizer_type]
        optimizer.add_param_group({"params": pg1, "weight_decay": weight_decay})
        optimizer.add_param_group({"params": pg2})

        #---------------------------------------#
        # Get the learning rate decay formula.
        #---------------------------------------#
        lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)

        #---------------------------------------#
        # Determine the length of each epoch.
        #---------------------------------------#
        epoch_step = num_train // batch_size
        epoch_step_val = num_val // batch_size

        if epoch_step == 0 or epoch_step_val == 0:
            raise ValueError("The dataset is too small to continue training. Please expand the dataset.")

        if ema:
            ema.updates = epoch_step * Init_Epoch

        #---------------------------------------#
        # Build the dataset loaders.
        #---------------------------------------#
        train_dataset = YoloDataset(train_lines, input_shape, num_classes, epoch_length=UnFreeze_Epoch,
                                    mosaic=mosaic, mixup=mixup, mosaic_prob=mosaic_prob, mixup_prob=mixup_prob, train=True, special_aug_ratio=special_aug_ratio)
        val_dataset = YoloDataset(val_lines, input_shape, num_classes, epoch_length=UnFreeze_Epoch,
                                  mosaic=False, mixup=False, mosaic_prob=0, mixup_prob=0, train=False, special_aug_ratio=0)

        if distributed:
            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True)
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
            batch_size = batch_size // ngpus_per_node
            shuffle = False
        else:
            train_sampler = None
            val_sampler = None
            shuffle = True

        gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers, pin_memory=True,
                         drop_last=True, collate_fn=yolo_dataset_collate, sampler=train_sampler,
                         worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed))
        gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers, pin_memory=True,
                             drop_last=True, collate_fn=yolo_dataset_collate, sampler=val_sampler,
                             worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed))

        #----------------------#
        # Record the mAP curve of evaluation.
        #----------------------#
        if local_rank == 0:
            eval_callback = EvalCallback(model, input_shape, class_names, num_classes, val_lines, log_dir, Cuda,
                                         eval_flag=eval_flag, period=eval_period)
        else:
            eval_callback = None

        #---------------------------------------#
        # Start model training.
        #---------------------------------------#
        for epoch in range(Init_Epoch, UnFreeze_Epoch):
            #---------------------------------------#
            # If part of the model is frozen for learning,
            # unfreeze it and set the parameters.
            #---------------------------------------#
            if epoch >= Freeze_Epoch and not UnFreeze_flag and Freeze_Train:
                batch_size = Unfreeze_batch_size

                #-------------------------------------------------------------------#
                # Adjust the learning rate adaptively based on the current batch_size.
                #-------------------------------------------------------------------#
                nbs = 64
                lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2
                lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4
                Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)
                Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)
                #---------------------------------------#
                # Get the learning rate decay formula.
                #---------------------------------------#
                lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)

                for param in model.backbone.parameters():
                    param.requires_grad = True

                epoch_step = num_train // batch_size
                epoch_step_val = num_val // batch_size

                if epoch_step == 0 or epoch_step_val == 0:
                    raise ValueError("The dataset is too small to continue training. Please expand the dataset.")

                if ema:
                    ema.updates = epoch_step * epoch

                if distributed:
                    batch_size = batch_size // ngpus_per_node

                gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers, pin_memory=True,
                                 drop_last=True, collate_fn=yolo_dataset_collate, sampler=train_sampler,
                                 worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed))
                gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers, pin_memory=True,
                                     drop_last=True, collate_fn=yolo_dataset_collate, sampler=val_sampler,
                                     worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed))

                UnFreeze_flag = True

            gen.dataset.epoch_now = epoch
            gen_val.dataset.epoch_now = epoch

            if distributed:
                train_sampler.set_epoch(epoch)

            set_optimizer_lr(optimizer, lr_scheduler_func, epoch)

            fit_one_epoch(model_train, model, ema, yolo_loss, loss_history, eval_callback, optimizer, epoch, epoch_step, epoch_step_val, gen, gen_val, UnFreeze_Epoch, Cuda, fp16, scaler, save_period, save_dir, local_rank)

            if distributed:
                dist.barrier()

        if local_rank == 0:
            loss_history.writer.close()
